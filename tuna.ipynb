{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eceb9c81-1fae-42dd-b037-872721458224",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10925d07-d585-43c2-997a-02de77d73b70",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from typing import *\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from constraints import (\n",
    "  Constraint, filter_df, ensure_constraint,\n",
    "  FIELD, NOT, OR, AND, EQ, RANGE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70cb4e8-c432-486d-aad5-bb09556f0eeb",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Set the paths\n",
    "We have a data directory `DATA_DIR`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3786a8fd-0c01-48ea-b6a4-088ff19441bf",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('data')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR: Final[Path] = Path('./data/')\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "DATA_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0ebfa3-2733-4319-9952-7acfcdae9c2a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "and the `manifest.json` inside it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "186e8518-a0bc-477e-9441-eab27e8cd4b9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('data/manifest.json')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MANIFEST_PATH: Final[Path] = DATA_DIR / 'manifest.json'\n",
    "MANIFEST_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cf8713-d4fa-4163-b2b4-bcc25937243d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Get the cache \n",
    "\n",
    "Import the cache and session types from `allensdk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0117776-b714-4402-8165-399e14c9ee91",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from allensdk.brain_observatory.ecephys.ecephys_project_cache import EcephysProjectCache\n",
    "from allensdk.brain_observatory.ecephys.ecephys_session import EcephysSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b616b4d-9e3e-4ac7-8dbe-0571a05fac6f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "and create type aliases for them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b692efe-389e-49c2-ad13-92a6e3a033c5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Cache: TypeAlias = EcephysProjectCache\n",
    "Session: TypeAlias = EcephysSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d52f35-afc0-4be4-91a6-56bbd4422459",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Create the global cache `CACHE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94924d72-2e7e-4888-b134-97664d9de467",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CACHE: Final[Cache] = EcephysProjectCache.from_warehouse(manifest=MANIFEST_PATH, timeout=30*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997b8ceb-e270-4b15-ab7c-e74ba13b9ec2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "and load the session table into `SESSIONS_TABLE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedd3d34-cae1-4f65-ae79-d0737b04a899",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SESSIONS_TABLE = CACHE.get_session_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc2b4e5-17dd-403f-901b-eacc645f633e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Constraints Intro\n",
    "\n",
    "The module `constraints` is a custom module defined for this project\n",
    "in `constraints.py`.  It provides a way to abstract away the process\n",
    "of filtering data.\n",
    "\n",
    "`constraints` defines the abstract `Constraint` type, which exposes\n",
    "methods, `Constraint.__contains__` and `Constraint.mask`.\n",
    "\n",
    "The function `c.__contains__(x)`, that is `x in c`, returns\n",
    "`True` if `x` satisfies the constraint `c`.\n",
    "\n",
    "The function `c.mask(df)` returns a mask for the pandas dataframe or\n",
    "series `df` which, when applied (as `df[c.mask(df)]`), returns the\n",
    "rows of `df` which satisfy `c`.\n",
    "\n",
    "Because `df[c.mask(df)]` is such a common thing to do, the function \n",
    "`filter_df` is defined as a shorthand:\n",
    "\n",
    "``` python\n",
    "def filter_df(df, constraint):\n",
    "return df[ensure_constraint(constraint).mask(df)]\n",
    "```\n",
    "\n",
    "The function `ensure_constraint` is the way to convert\n",
    "non-`Constraint` objects into `Constraint` objects, such that our\n",
    "methods are well-defined.\n",
    "\n",
    "## Writing Constraints\n",
    "The following `Constraint` classes are defined:\n",
    "\n",
    "### Literal Constraint\n",
    "`number`  \n",
    "`string`  \n",
    "`EQ(obj)`\n",
    "  \n",
    "A literal constraint will only match objects equal to `obj`.  That is,\n",
    "`x in EQ(obj)` iff `x == obj`.\n",
    "\n",
    "Numbers, strings, and other literal objects (excluding iterable\n",
    "objects and mapping, see `OR` and `FIELD`) are treated as `EQ`\n",
    "constraints when passed through `ensure_constraint`.  Thus,\n",
    "`filter_df(df, 5)` would return rows of `df` equal to `5`.\n",
    "\n",
    "### Range Constraint\n",
    "`RANGE(lb, ub, lb_strict=False, ub_strict=True)`\n",
    "\n",
    "A range constraint matches objects which are between `lb` and `ub`.\n",
    "The bounds are strict if `lb_strict` and `ub_strict` are `True`.\n",
    "\n",
    "If `lb` or `ub` is `None`, then the constraint has no lower or upper\n",
    "bounds respectively.\n",
    "\n",
    "### Or Constraint\n",
    "`[Constraint]`  \n",
    "`OR(Iterable[Constraint])`  \n",
    "`OR(Constraint...)`\n",
    "\n",
    "The logical-or of the supplied constraints.  An object matches the\n",
    "`OR` constraint if it matches any of its sub-constraints.\n",
    "\n",
    "A sequence of constraints `[constraint...]` is equivalent to\n",
    "`OR(constraint...)`.\n",
    "\n",
    "### And Constraint\n",
    "`AND(Iterable[Constraint])`  \n",
    "`AND(Constraint...)`\n",
    "\n",
    "The logical-and of the supplied constraints.  An object matches the\n",
    "`AND` constraint if it matches all of its sub-constraints.\n",
    "\n",
    "### Not Constraint\n",
    "`NOT(Constraint)`\n",
    "\n",
    "The negation of the supplied constraint.  An object matches the\n",
    "`NOT` constraint only if it _doesn't_ match its sub-constraint.\n",
    "\n",
    "### Field Constraint\n",
    "`{'field': constraint...}`  \n",
    "`FIELD(field=constraint...)`\n",
    "\n",
    "This constraint matches a field of object against the corresponding\n",
    "constraint.\n",
    "\n",
    "There are two ways to think about this: Given a pandas dataframe\n",
    "`df`, if you wanted to add a constraint `constraint` to the column\n",
    "named `length`, you would use the constraint\n",
    "``` python \n",
    "FIELD(length=constraint)\n",
    "```\n",
    "and if you further wanted to add a constraint `constraint2` to the \n",
    "column named `item_id`, you would do\n",
    "``` python\n",
    "FIELD(length=constraint, item_id=constraint2)\n",
    "```\n",
    "\n",
    "Of course, instead, you can also use a dict.  The above constraint\n",
    "is equivalent to\n",
    "``` python\n",
    "{'length': constraint, 'item_id': constraint2}\n",
    "```\n",
    "\n",
    "There is nothing special about the `FIELD` constraint, so it can be\n",
    "passed to `AND`, `OR`, and `NOT` just the way you would pass other\n",
    "constraints.  This allows the writing of a rich set of constraints.\n",
    "\n",
    "### Examples\n",
    "If you want to get the rows in `CURRENT_SESSION.units` where the\n",
    "`isi_violations` is less than 0.7, you would do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319e8f0b-39af-411c-87d5-28c3e0ffefad",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filter_df(CURRENT_SESSION.units, RANGE(None, 0.7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb51acea-0268-407f-baa7-45e9d8a23371",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Org Babel Setup\n",
    "\n",
    "``` python\n",
    "def assStr (name, literal=True):\n",
    "  f = repr if literal else str\n",
    "  return name + \" = \" + f(eval(name))\n",
    "```\n",
    "\n",
    "``` elisp\n",
    "(message \"%s\" v)\n",
    "```\n",
    "\n",
    "``` elisp\n",
    "(when (eq 'hline (cadr table))\n",
    "  (setq table (cddr table)))\n",
    "(cl-flet ((ellide-list (list length &optional (ellision \"...\"))\n",
    "              (if (and length (length> list length))\n",
    "                  (append (seq-subseq list 0 (/ length 2))\n",
    "                          (list ellision)\n",
    "                          (seq-subseq list (- (length list) (/ length 2))))\n",
    "                list)))\n",
    "    (mapcar (lambda (row) (if (listp row) (ellide-list row ncols) row))\n",
    "            (ellide-list table nrows (make-list (length (car table)) \"...\"))))\n",
    "```\n",
    "\n",
    "``` elisp\n",
    "(cl-mapcar #'list (number-sequence start (+ start (length list))) list)\n",
    "```\n",
    "\n",
    "``` elisp\n",
    "(cl-loop with i = (1- start)\n",
    "         for startp = t then nil\n",
    "         for tail on table\n",
    "         collect\n",
    "         (cond ((atom (car tail)) (car tail))\n",
    "               ((and startp (eq 'hline (cadr tail)))\n",
    "                (cons index-name (car tail)))\n",
    "               (t (cons (cl-incf i) (car tail)))))\n",
    "```\n",
    "\n",
    "# Setup\n",
    "\n",
    "``` python\n",
    "from typing import *\n",
    "import pandas as pd\n",
    "```\n",
    "\n",
    "# Download Sessions\n",
    "\n",
    "Set `data_dir` and ensure it exists.\n",
    "\n",
    "``` python\n",
    "from pathlib import Path\n",
    "data_dir: Final[Path] = Path('./data/')\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "```\n",
    "\n",
    "Set `manifest_path`.\n",
    "\n",
    "``` python\n",
    "manifest_path: Final[Path] = data_dir / 'manifest.json'\n",
    "```\n",
    "\n",
    "Create and initialize the project cache object\n",
    "\n",
    "``` python\n",
    "from allensdk.brain_observatory.ecephys.ecephys_project_cache import EcephysProjectCache\n",
    "cache: Final = EcephysProjectCache.from_warehouse(manifest=manifest_path, timeout=30*60)\n",
    "```\n",
    "\n",
    "and obtain the sessions\n",
    "\n",
    "``` python\n",
    "sessions = cache.get_session_table()\n",
    "```\n",
    "\n",
    "Extract the session ids from `sessions` into `session_ids`\n",
    "\n",
    "``` python\n",
    "session_ids: Final[Sequence[int]] = list(sessions.index)\n",
    "```\n",
    "\n",
    "Extract a single session into `session`:\n",
    "\n",
    "``` python\n",
    "assert session_id in session_ids\n",
    "session = cache.get_session_data(session_id) \n",
    "session.metadata\n",
    "```\n",
    "\n",
    "``` python\n",
    "session.units.head()\n",
    "```\n",
    "\n",
    "``` python\n",
    "session.stimulus_conditions.head()\n",
    "```\n",
    "\n",
    "``` python\n",
    "session.stimulus_conditions['stimulus_name'].value_counts()\n",
    "```\n",
    "\n",
    "``` python\n",
    "grouped_stimulus_presentations = session.stimulus_presentations.groupby('stimulus_name')\n",
    "```\n",
    "\n",
    "``` python\n",
    "total_durations = grouped_stimulus_presentations['duration'].sum()\n",
    "```\n",
    "\n",
    "``` python\n",
    "def presentation_type_spike_times(expr = None, mask = None, unit_names = session.units.index):\n",
    "  presentations = session.stimulus_presentations\n",
    "  if mask is not None:\n",
    "    presentations = presentations[mask]\n",
    "  if expr is not None:\n",
    "    presentations = presentations.query(expr)\n",
    "  return session.presentationwise_spike_times(presentations['stimulus_condition_id'], unit_names)\n",
    "\n",
    "presentation_type_spike_times(expr=\"`stimulus_name` == 'drifting_gratings'\").head(10)\n",
    "```\n",
    "\n",
    "``` python\n",
    "spike_times_with_presentations_condition_names = \\\n",
    "  pd.merge(\n",
    "    session.presentationwise_spike_times(\n",
    "      session.stimulus_presentations['stimulus_condition_id'],\n",
    "      session.units.index).reset_index(),\n",
    "    session.stimulus_presentations['stimulus_name'],\n",
    "    how='left',\n",
    "    on='stimulus_presentation_id'\n",
    "  )\n",
    "```\n",
    "\n",
    "``` python\n",
    "def get_spike_times_df(unit_ids: Optional[Sequence[int]]=None):\n",
    "  return pd.concat((\n",
    "    (_df := pd.DataFrame(unit_spike_times, columns=['spike_time']),\n",
    "     _df.insert(0,'unit_id',unit_id),\n",
    "     _df)[-1]\n",
    "    for (unit_id, unit_spike_times) in session.spike_times.items()\n",
    "    if unit_ids is None or unit_id in unit_ids\n",
    "  ), ignore_index=True, copy=False)\n",
    "\n",
    "spike_times_df = get_spike_times_df()\n",
    "```\n",
    "\n",
    "``` python\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "/home/thuna/temp/neuroscience-project/MMN-Group-Project/venv/bin/python",
    "-Xfrozen_modules=off",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "venv",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": {
    "debugger": true
   },
   "name": "venv"
  },
  "name": "tuna.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
