{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Org Babel Setup\n",
    "\n",
    "``` python\n",
    "def assStr (name, literal=True):\n",
    "  f = repr if literal else str\n",
    "  return name + \" = \" + f(eval(name))\n",
    "```\n",
    "\n",
    "``` elisp\n",
    "(message \"%s\" v)\n",
    "```\n",
    "\n",
    "``` elisp\n",
    "(when (eq 'hline (cadr table))\n",
    "  (setq table (cddr table)))\n",
    "(cl-flet ((ellide-list (list length &optional (ellision \"...\"))\n",
    "              (if (and length (length> list length))\n",
    "                  (append (seq-subseq list 0 (/ length 2))\n",
    "                          (list ellision)\n",
    "                          (seq-subseq list (- (length list) (/ length 2))))\n",
    "                list)))\n",
    "    (mapcar (lambda (row) (if (listp row) (ellide-list row ncols) row))\n",
    "            (ellide-list table nrows (make-list (length (car table)) \"...\"))))\n",
    "```\n",
    "\n",
    "``` elisp\n",
    "(cl-mapcar #'list (number-sequence start (+ start (length list))) list)\n",
    "```\n",
    "\n",
    "``` elisp\n",
    "(cl-loop with i = (1- start)\n",
    "         for startp = t then nil\n",
    "         for tail on table\n",
    "         collect\n",
    "         (cond ((atom (car tail)) (car tail))\n",
    "               ((and startp (eq 'hline (cadr tail)))\n",
    "                (cons index-name (car tail)))\n",
    "               (t (cons (cl-incf i) (car tail)))))\n",
    "```\n",
    "\n",
    "# Setup\n",
    "\n",
    "``` python\n",
    "from typing import *\n",
    "import pandas as pd\n",
    "```\n",
    "\n",
    "# Download Sessions\n",
    "\n",
    "Set `data_dir` and ensure it exists.\n",
    "\n",
    "``` python\n",
    "from pathlib import Path\n",
    "data_dir: Final[Path] = Path('./data/')\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "```\n",
    "\n",
    "Set `manifest_path`.\n",
    "\n",
    "``` python\n",
    "manifest_path: Final[Path] = data_dir / 'manifest.json'\n",
    "```\n",
    "\n",
    "Create and initialize the project cache object\n",
    "\n",
    "``` python\n",
    "from allensdk.brain_observatory.ecephys.ecephys_project_cache import EcephysProjectCache\n",
    "cache: Final = EcephysProjectCache.from_warehouse(manifest=manifest_path, timeout=30*60)\n",
    "```\n",
    "\n",
    "and obtain the sessions\n",
    "\n",
    "``` python\n",
    "sessions = cache.get_session_table()\n",
    "```\n",
    "\n",
    "Extract the session ids from `sessions` into `session_ids`\n",
    "\n",
    "``` python\n",
    "session_ids: Final[Sequence[int]] = list(sessions.index)\n",
    "```\n",
    "\n",
    "Extract a single session into `session`:\n",
    "\n",
    "``` python\n",
    "assert session_id in session_ids\n",
    "session = cache.get_session_data(session_id) \n",
    "session.metadata\n",
    "```\n",
    "\n",
    "``` python\n",
    "session.units.head()\n",
    "```\n",
    "\n",
    "``` python\n",
    "session.stimulus_conditions.head()\n",
    "```\n",
    "\n",
    "``` python\n",
    "session.stimulus_conditions['stimulus_name'].value_counts()\n",
    "```\n",
    "\n",
    "``` python\n",
    "grouped_stimulus_presentations = session.stimulus_presentations.groupby('stimulus_name')\n",
    "```\n",
    "\n",
    "``` python\n",
    "total_durations = grouped_stimulus_presentations['duration'].sum()\n",
    "```\n",
    "\n",
    "``` python\n",
    "def presentation_type_spike_times(expr = None, mask = None, unit_names = session.units.index):\n",
    "  presentations = session.stimulus_presentations\n",
    "  if mask is not None:\n",
    "    presentations = presentations[mask]\n",
    "  if expr is not None:\n",
    "    presentations = presentations.query(expr)\n",
    "  return session.presentationwise_spike_times(presentations['stimulus_condition_id'], unit_names)\n",
    "\n",
    "presentation_type_spike_times(expr=\"`stimulus_name` == 'drifting_gratings'\").head(10)\n",
    "```\n",
    "\n",
    "``` python\n",
    "spike_times_with_presentations_condition_names = \\\n",
    "  pd.merge(\n",
    "    session.presentationwise_spike_times(\n",
    "      session.stimulus_presentations['stimulus_condition_id'],\n",
    "      session.units.index).reset_index(),\n",
    "    session.stimulus_presentations['stimulus_name'],\n",
    "    how='left',\n",
    "    on='stimulus_presentation_id'\n",
    "  )\n",
    "```\n",
    "\n",
    "``` python\n",
    "def get_spike_times_df(unit_ids: Optional[Sequence[int]]=None):\n",
    "  return pd.concat((\n",
    "    (_df := pd.DataFrame(unit_spike_times, columns=['spike_time']),\n",
    "     _df.insert(0,'unit_id',unit_id),\n",
    "     _df)[-1]\n",
    "    for (unit_id, unit_spike_times) in session.spike_times.items()\n",
    "    if unit_ids is None or unit_id in unit_ids\n",
    "  ), ignore_index=True, copy=False)\n",
    "\n",
    "spike_times_df = get_spike_times_df()\n",
    "```\n",
    "\n",
    "``` python\n",
    "\n",
    "```"
   ],
   "id": "cb51acea-0268-407f-baa7-45e9d8a23371"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
